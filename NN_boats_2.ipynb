{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NN_boats_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F8SaYI2EK1-jaNoGeag3Kp2CwnWDJjw5",
      "authorship_tag": "ABX9TyNXEgM9jrpPnATWi3OSMRxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirovix/CV_final_project/blob/main/NN_boats_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPKlOJ-J-juS"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from imutils.object_detection import non_max_suppression\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import json\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yIWKw1rGK5G"
      },
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    assert bb1['x1'] < bb1['x2']\n",
        "    assert bb1['y1'] < bb1['y2']\n",
        "    assert bb2['x1'] < bb2['x2']\n",
        "    assert bb2['y1'] < bb2['y2']\n",
        "    x_left = max(bb1['x1'], bb2['x1'])\n",
        "    y_top = max(bb1['y1'], bb2['y1'])\n",
        "    x_right = min(bb1['x2'], bb2['x2'])\n",
        "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
        "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFv0COpUNu9m"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.epoch,history.history['loss'])\n",
        "  plt.plot(history.epoch,history.history['val_loss'])\n",
        "  plt.title('loss')\n",
        "\n",
        "def plot_accuracy(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.epoch,history.history['accuracy'])\n",
        "  plt.plot(history.epoch,history.history['val_accuracy'])\n",
        "  plt.title('accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLc1-GRHfamd"
      },
      "source": [
        "def non_max_suppression_slow(boxes, overlapThresh):\n",
        "\t# if there are no boxes, return an empty list\n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        "\t# initialize the list of picked indexes\n",
        "\tpick = []\n",
        "\t# grab the coordinates of the bounding boxes\n",
        "\tx1 = boxes[:,0]\n",
        "\ty1 = boxes[:,1]\n",
        "\tx2 = boxes[:,2]\n",
        "\ty2 = boxes[:,3]\n",
        "\t# compute the area of the bounding boxes and sort the bounding\n",
        "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
        "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "\tidxs = np.argsort(y2)\n",
        "  # keep looping while some indexes still remain in the indexes\n",
        "\t# list\n",
        "\twhile len(idxs) > 0:\n",
        "\t\t# grab the last index in the indexes list, add the index\n",
        "\t\t# value to the list of picked indexes, then initialize\n",
        "\t\t# the suppression list (i.e. indexes that will be deleted)\n",
        "\t\t# using the last index\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        "\t\tsuppress = [last]\n",
        "    \t\t# loop over all indexes in the indexes list\n",
        "\t\tfor pos in range(0, last):\n",
        "\t\t\t# grab the current index\n",
        "\t\t\tj = idxs[pos]\n",
        "\t\t\t# find the largest (x, y) coordinates for the start of\n",
        "\t\t\t# the bounding box and the smallest (x, y) coordinates\n",
        "\t\t\t# for the end of the bounding box\n",
        "\t\t\txx1 = max(x1[i], x1[j])\n",
        "\t\t\tyy1 = max(y1[i], y1[j])\n",
        "\t\t\txx2 = min(x2[i], x2[j])\n",
        "\t\t\tyy2 = min(y2[i], y2[j])\n",
        "\t\t\t# compute the width and height of the bounding box\n",
        "\t\t\tw = max(0, xx2 - xx1 + 1)\n",
        "\t\t\th = max(0, yy2 - yy1 + 1)\n",
        "\t\t\t# compute the ratio of overlap between the computed\n",
        "\t\t\t# bounding box and the bounding box in the area list\n",
        "\t\t\toverlap = float(w * h) / area[j]\n",
        "\t\t\t# if there is sufficient overlap, suppress the\n",
        "\t\t\t# current bounding box\n",
        "\t\t\tif overlap > overlapThresh:\n",
        "\t\t\t\tsuppress.append(pos)\n",
        "\t\t# delete all indexes from the index list that are in the\n",
        "\t\t# suppression list\n",
        "\t\tidxs = np.delete(idxs, suppress)\n",
        "\t# return only the bounding boxes that were picked\n",
        "\treturn boxes[pick]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOuIi8zNsGlf",
        "outputId": "4266f3ea-0094-436f-dd5b-58dc463722a2"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/dataset_boats/label_multi.json') as json_file:\n",
        "    json_file = json.load(json_file)\n",
        "\n",
        "i=1\n",
        "train_images=[]\n",
        "train_labels=[]\n",
        "\n",
        "for row in json_file:\n",
        "  if(i==1433):\n",
        "    break;\n",
        "  if(i%20==0):\n",
        "    print(i)\n",
        "  i=i+1\n",
        "  gtvalues=[]\n",
        "  for col in row['Label']['objects']:\n",
        "    if(len(row['Label']) != 0):\n",
        "      x_start = int(col['bbox']['left'])\n",
        "      y_start = int(col['bbox']['top'])\n",
        "      x_end = int(col['bbox']['left'] + col['bbox']['width'])\n",
        "      y_end = int(col['bbox']['top'] + col['bbox']['height'])\n",
        "      gtvalues.append({\"x1\":x_start,\"x2\":x_end,\"y1\":y_start,\"y2\":y_end})\n",
        "\n",
        "  image_path = \"/content/drive/MyDrive/dataset_boats/train/\" + row['External ID']\n",
        "  cv_image = cv2.imread(image_path)\n",
        "\n",
        "  ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "  ss.setBaseImage(cv_image)\n",
        "  ss.switchToSelectiveSearchFast()\n",
        "  ssresults = ss.process()\n",
        "\n",
        "  imout = cv_image.copy()\n",
        "  counter = 0\n",
        "  falsecounter = 0\n",
        "  flag = 0\n",
        "  fflag = 0\n",
        "  bflag = 0\n",
        "  for e,result in enumerate(ssresults):\n",
        "    if e < 2000 and flag == 0:\n",
        "      for gtval in gtvalues:\n",
        "\n",
        "        x, y, w, h = result\n",
        "        iou = get_iou(gtval,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n",
        "\n",
        "        if counter < 2:\n",
        "          if iou > 0.95:\n",
        "            resized = cv2.resize(imout[y:y+h,x:x+w], (224,224), interpolation = cv2.INTER_AREA)\n",
        "            train_images.append(resized)\n",
        "            train_labels.append(1)\n",
        "            counter += 1\n",
        "        else :\n",
        "          fflag =1\n",
        "        if falsecounter < 5:\n",
        "          if h*w < 3000:\n",
        "            continue\n",
        "          if iou < 0.1:\n",
        "            resized = cv2.resize(imout[y:y+h,x:x+w], (224,224), interpolation = cv2.INTER_AREA)\n",
        "            train_images.append(resized)\n",
        "            train_labels.append(0)\n",
        "            falsecounter += 1\n",
        "        else :\n",
        "          bflag = 1\n",
        "      if fflag == 1 and bflag == 1:\n",
        "        flag = 1\n",
        "\n",
        "#print(gtvalues) \n",
        "print(len(train_images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "400\n",
            "420\n",
            "440\n",
            "460\n",
            "480\n",
            "500\n",
            "520\n",
            "540\n",
            "560\n",
            "580\n",
            "600\n",
            "620\n",
            "640\n",
            "660\n",
            "680\n",
            "700\n",
            "720\n",
            "740\n",
            "760\n",
            "780\n",
            "800\n",
            "820\n",
            "840\n",
            "860\n",
            "880\n",
            "900\n",
            "920\n",
            "940\n",
            "960\n",
            "980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccBUB6uZtXZI"
      },
      "source": [
        "from imutils import paths\n",
        "imagePaths = sorted(list(paths.list_images(\"/content/drive/MyDrive/dataset_boats/buildings/\"))) \n",
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath)\n",
        "  imout = image.copy()\n",
        "  ss.setBaseImage(image)\n",
        "  ss.switchToSelectiveSearchFast()\n",
        "  ssresults = ss.process()\n",
        "  flag=0\n",
        "  falsecounter = 0\n",
        "  for e,result in enumerate(ssresults):\n",
        "    if e < 2000 and flag == 0:\n",
        "      x, y, w, h = result\n",
        "      if h*w < 3000:\n",
        "        continue\n",
        "      if falsecounter < 3:\n",
        "        resized = cv2.resize(imout[y:y+h,x:x+w], (224,224), interpolation = cv2.INTER_AREA)\n",
        "        train_images.append(resized)\n",
        "        train_labels.append(0)\n",
        "        falsecounter += 1\n",
        "      else :\n",
        "        flag = 1\n",
        "print(len(train_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx4j6Hs18QOr"
      },
      "source": [
        "X_new = np.array(train_images)\n",
        "y_new = np.array(train_labels)\n",
        "\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.layers import Dense\n",
        "from keras import Model\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "vggmodel = MobileNetV2(weights='imagenet', include_top=True)\n",
        "\n",
        "X=vggmodel.layers[-2].output\n",
        "predictions = Dense(2, activation=\"softmax\")(X)\n",
        "model_final = Model(inputs = vggmodel.input, outputs = predictions)\n",
        "opt = Adam(lr=0.0001)\n",
        "model_final.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])\n",
        "model_final.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzUoOTzi9Eud"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "class MyLabelBinarizer(LabelBinarizer):\n",
        "    def transform(self, y):\n",
        "        Y = super().transform(y)\n",
        "        if self.y_type_ == 'binary':\n",
        "            return np.hstack((Y, 1-Y))\n",
        "        else:\n",
        "            return Y\n",
        "    def inverse_transform(self, Y, threshold=None):\n",
        "        if self.y_type_ == 'binary':\n",
        "            return super().inverse_transform(Y[:, 0], threshold)\n",
        "        else:\n",
        "            return super().inverse_transform(Y, threshold)\n",
        "lenc = MyLabelBinarizer()\n",
        "Y =  lenc.fit_transform(y_new)\n",
        "#X_train, X_test , y_train, y_test = train_test_split(X_new,Y,test_size=0.10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new,Y,test_size=0.10)\n",
        "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPEZMpuE9K1D"
      },
      "source": [
        "#mean = np.mean(X_train, axis = 0)\n",
        "#std = np.std(X_train, axis = 0)\n",
        "\n",
        "#X_train = (X_train - mean) /  std\n",
        "#X_val = (X_val - mean) /  std\n",
        "#X_test = (X_test - mean) /  std\n",
        "\n",
        "trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "X_train = trdata.flow(x=X_train, y=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo4bSz1W9LtH"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "#checkpoint = ModelCheckpoint(\"ieeercnn_vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "#history = model_final.fit_generator(generator=X_train, steps_per_epoch= 10, epochs= 5, validation_data= X_val, validation_steps=2)\n",
        "history = model_final.fit(X_train , epochs=10, batch_size=16 ,validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpvU9ibsOM2u"
      },
      "source": [
        "plot_loss(history)\n",
        "plot_accuracy(history)\n",
        "\n",
        "scores = model_final.evaluate(X_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (model_final.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3cIDmwf9OpK"
      },
      "source": [
        "image_path = \"/content/drive/MyDrive/dataset_boats/train/20130412_150512_31795.jpg\" #20130412_151959_34446 #\"/content/drive/MyDrive/dataset_boats/venice_dataset/07.png\" \n",
        "image_path = \"/content/drive/MyDrive/dataset_boats/venice_dataset/10.png\"\n",
        "#image_path = \"/content/drive/MyDrive/dataset_boats/Kaggle_ships/01.jpg\" \n",
        "#image_path = \"/content/drive/MyDrive/dataset_boats/other_boats/a.jpg\"\n",
        "# speed-up using multithreads\n",
        "\n",
        "import tensorflow as tf\n",
        "model_final = tf.keras.models.load_model(\"/content/drive/MyDrive/dataset_boats/model7.h5\")\n",
        "cv2.setUseOptimized(True)  # Use optimization\n",
        "#cv2.setNumThreads(8)  # Turn on multithreaded computing\n",
        "img = cv2.imread(image_path)\n",
        "imout = img.copy()\n",
        "cv2.resize(img, (8,8), interpolation = cv2.INTER_AREA)\n",
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "ss.setBaseImage(img)\n",
        "ss.switchToSingleStrategy()\n",
        "#ss.switchToSelectiveSearchFast(10,10,0.001)\n",
        "ssresults = ss.process()\n",
        "boundingBoxes = []\n",
        "score = []\n",
        "for i,result in enumerate(ssresults):\n",
        "  if(i>3000):\n",
        "    break\n",
        "  if(i%250==0):\n",
        "    print(i)\n",
        "  x,y,w,h = result\n",
        "  if ((w*h)<5000) or (h > 220):\n",
        "    continue\n",
        "  timage = imout[y:y+h,x:x+w]\n",
        "  resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "  img = np.expand_dims(resized, axis=0)\n",
        "  out= model_final.predict(img)\n",
        "  if out[0][0] > 0.95:\n",
        "    #cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 255), 1, cv2.LINE_AA)\n",
        "    cv2_imshow(resized)\n",
        "    boundingBoxes.append([x, y, x+w, y+h])\n",
        "    #score.append(out[0][0])\n",
        "\n",
        "boundingBoxes = np.array(boundingBoxes)\n",
        "pick = non_max_suppression_slow(boundingBoxes, 0.3)\n",
        "#cv2.NMSBoxes(boundingBoxes, score, 0.3, 0.1)\n",
        "for (x, y, x_2, y_3) in pick:\n",
        "   cv2.rectangle(imout, (x, y), (x_2, y_3), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "cv2_imshow(imout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAxYVd2KRwGd"
      },
      "source": [
        "model_final.save(\"/content/drive/MyDrive/dataset_boats/model8.h5\", overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WuXOQ6WROj0d",
        "outputId": "c7b2f99e-330f-4ed1-905c-58e2901a5d13"
      },
      "source": [
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2 \n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/dataset_boats/model6.h5')\n",
        "full_model = tf.function(lambda inputs: model(inputs))    \n",
        "full_model = full_model.get_concrete_function(tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
        "# Get frozen ConcreteFunction    \n",
        "frozen_func = convert_variables_to_constants_v2(full_model)    \n",
        "frozen_func.graph.as_graph_def()\n",
        "# Save frozen graph from frozen ConcreteFunction to hard drive    \n",
        "tf.io.write_graph(graph_or_graph_def=frozen_func.graph, logdir=\"/content/drive/MyDrive/dataset_boats/\", name=\"model.pb\", as_text=False)\n",
        "#tf.io.write_graph(graph_or_graph_def=frozen_func.graph, logdir=\"/content/drive/MyDrive/dataset_boats/\", name=\"model.pbtxt\", as_text=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/dataset_boats/model.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4LD8hmZHR5b7",
        "outputId": "66d9ab12-d496-4435-bcc3-5c696ce1bb95"
      },
      "source": [
        "from keras import backend as K\n",
        "with open('/content/drive/MyDrive/dataset_boats/model.pb', 'rb') as f:\n",
        "    graph_def = tf.compat.v1.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "\n",
        "with K.get_session() as sess:\n",
        "    sess.graph.as_default()\n",
        "    tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "for i in reversed(range(len(graph_def.node))):\n",
        "    if graph_def.node[i].op == 'Const':\n",
        "        del graph_def.node[i]\n",
        "    for attr in ['T', 'data_format', 'Tshape', 'N', 'Tidx', 'Tdim','use_cudnn_on_gpu', 'Index', 'Tperm', 'is_training','Tpaddings']:\n",
        "        if attr in graph_def.node[i].attr:\n",
        "             del graph_def.node[i].attr[attr]\n",
        "\n",
        "# Save stripped model.\n",
        "tf.io.write_graph(graph_def, logdir=\"/content/drive/MyDrive/dataset_boats/\", name=\"model.pbtxt\", as_text=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/dataset_boats/model.pbtxt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2sjy1Y1UT_Y"
      },
      "source": [
        "# Architecture and weight files for the model\n",
        "textGraph = \"/content/drive/MyDrive/dataset_boats/model.pbtxt\"\n",
        "modelWeights = \"/content/drive/MyDrive/dataset_boats/model.pb\"\n",
        "# Load the network\n",
        "net = cv2.dnn.readNetFromTensorflow(modelWeights, textGraph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3nW6o9OtomO"
      },
      "source": [
        "!pip install opencv-python==4.5.1.48\n",
        "!pip install opencv-contrib-python==4.5.1.48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pSiuKqLQCkB",
        "outputId": "5f79a9ba-7c78-4438-c4df-22f4a914f9c7"
      },
      "source": [
        "image_path = \"/content/drive/MyDrive/dataset_boats/venice_dataset/07.png\"\n",
        "image_path = \"/content/drive/MyDrive/dataset_boats/Kaggle_ships/10.jpg\"\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "ss.setBaseImage(img)\n",
        "ss.switchToSingleStrategy()\n",
        "#ss.switchToSelectiveSearchFast()\n",
        "ssresults = ss.process()\n",
        "imout = img.copy()\n",
        "boundingBoxes = []\n",
        "for i,result in enumerate(ssresults):\n",
        "  if(i>2000):\n",
        "    break\n",
        "  if(i%250==0):\n",
        "    print(i)\n",
        "  x,y,w,h = result\n",
        "  timage = imout[y:y+h,x:x+w]\n",
        "  resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "  img = cv2.dnn.blobFromImage(resized, size=(224, 224), swapRB=False, crop=False)\n",
        "  net.setInput(img)\n",
        "  out = net.forward()\n",
        "  if out[0][0] > 0.60:\n",
        "    #cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "    boundingBoxes.append([x, y, x+w, y+h])\n",
        "\n",
        "boundingBoxes = np.array(boundingBoxes)\n",
        "pick = non_max_suppression_slow(boundingBoxes, 0.1)\n",
        "for (x, y, x_2, y_3) in pick:\n",
        "   cv2.rectangle(imout, (x, y), (x_2, y_3), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "cv2_imshow(imout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "250\n",
            "500\n",
            "750\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqhZXrNq9wF_"
      },
      "source": [
        "print(boundingBoxes)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}