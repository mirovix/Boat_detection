{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_boats.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1T704nvB2Ecz4rA5JbKqCxunY6dTWLoNh",
      "authorship_tag": "ABX9TyPuIx+l9YV6l2HUjBredA7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirovix/CV_final_project/blob/main/NN_boats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFtjNmc4faB5"
      },
      "source": [
        "import json\n",
        "import io\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6PawTwU0m99"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/dataset_boats/label.json') as json_file:\n",
        "    json_file = json.load(json_file)\n",
        "\n",
        "#print(len(json_file[30]['Label']))\n",
        "\n",
        "x_start, y_start, x_end, y_end, name_pic = [],[],[],[],[]\n",
        "for row in json_file:\n",
        "  if(len(row['Label']) == 0):\n",
        "    continue\n",
        "  name_pic.append(row['External ID'])\n",
        "  x_start.append(float(row['Label']['objects'][0]['bbox']['left']))\n",
        "  y_start.append(float(row['Label']['objects'][0]['bbox']['top']))\n",
        "  x_end.append(float(row['Label']['objects'][0]['bbox']['left'] + row['Label']['objects'][0]['bbox']['width']))\n",
        "  y_end.append(float(row['Label']['objects'][0]['bbox']['top'] + row['Label']['objects'][0]['bbox']['height']))\n",
        "\n",
        "i=0\n",
        "width = 32\n",
        "height = 32\n",
        "data,targets = [],[]\n",
        "for image in glob.glob(\"/content/drive/MyDrive/dataset_boats/train/*.jpg\"):\n",
        "   cv_image = cv2.imread(image)\n",
        "   cv_image = cv2.resize(cv_image, (height, width))\n",
        "   data.append(img_to_array(cv_image))\n",
        "   targets.append((x_start[i], y_start[i], x_end[i], y_end[i]))\n",
        "   #h.append(cv_image.shape[0])\n",
        "   #w.append(cv_image.shape[1])\n",
        "   if(i==300):\n",
        "    break\n",
        "   i=i+1\n",
        "\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpUxArvoRfMl"
      },
      "source": [
        "\t# scale the bounding box coordinates relative to the spatial\n",
        "\t# dimensions of the input image\n",
        "for i in range(len(data)):\n",
        "  x_start[i] = x_start[i] / w[i]\n",
        "  y_start[i] = y_start[i] / h[i]\n",
        "  x_end[i] = x_end[i] / w[i]\n",
        "  y_end[i] = y_end[i] / h[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIP5_YkS0IUv"
      },
      "source": [
        "targets = []\n",
        "i=0\n",
        "for image in glob.glob(\"/content/drive/MyDrive/dataset_boats/train/*.jpg\"):\n",
        "  image_loaded = load_img(image, target_size=(224, 224))\n",
        "  data.append(img_to_array(image_loaded))\n",
        "  targets.append((x_start[i], y_start[i], x_end[i], y_end[i]))\n",
        "  if(i==13):\n",
        "    break\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGrgVOV15LPr"
      },
      "source": [
        "# convert the data and targets to NumPy arrays, scaling the input\n",
        "# pixel intensities from the range [0, 255] to [0, 1]\n",
        "#data = np.array(data, dtype=\"float32\") / 255.0\n",
        "#targets = np.array(targets, dtype=\"float32\")\n",
        "# partition the data into training and testing splits using 90% of\n",
        "# the data for training and the remaining 10% for testing\n",
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "targets = np.array(targets, dtype=\"float32\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.10, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bdk2go053ao"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.epoch,history.history['loss'])\n",
        "  plt.plot(history.epoch,history.history['val_loss'])\n",
        "  plt.title('loss')\n",
        "\n",
        "def plot_accuracy(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.epoch,history.history['accuracy'])\n",
        "  plt.plot(history.epoch,history.history['val_accuracy'])\n",
        "  plt.title('accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA46MLaz56JY"
      },
      "source": [
        "print(y_train[0].shape)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=[3,3], activation='tanh', input_shape=[32, 32, 3]),\n",
        "    keras.layers.MaxPool2D(pool_size=[2,2]),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=[2,2], activation='tanh'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  \n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=256 ,validation_data=(X_test, y_test))\n",
        "\n",
        "plot_loss(history)\n",
        "plot_accuracy(history)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(\" %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "print(\"----------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}